# ML-7
<h2>Прогнозирование биологического ответа</h2>
<div>
Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776).
<ul>Данные представлены в формате CSV.  Каждая строка представляет молекулу. 
<li>Первый столбец Activity содержит экспериментальные данные, описывающие фактический биологический ответ [0, 1];</li>
<li>Остальные столбцы D1-D1776 представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.</li>
</ul>
<p>Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50.</p>
</div>
<div>
<h3>Оптимизация гиперпараметров модели</h3>
<ul>По условию задачи требуется использовать все четыре метода оптимизации хотя бы один раз:
<li>GridSeachCV,</li>
<li>RandomizedSearchCV,</li>
<li>Hyperopt,</li>
<li>Optuna</li>
</ul>
<div>
<ol>Работа состоит из следующих этапов:
<li>загрузка данных;</li>
<li>разделение выборки на тренировочную и тестовую;</li>
<li>логистическая регрессия;</li>
<li>случайный лес.</li>
</ol>
</div>
<div>
<h3>Логистическая регрессия</h3>
<p>На первом шаге обучение модели велось без дополнительных настроек.</br>
<ol>Получены следующие результаты для метрики F1:
<li>тренировочный набор - 0.87;</li>
<li>тестовый набор - 0.79</li>
</ol>
</p>
<p>Далее использовался метод оптимизации GridSearchCV.</br>
Использование набора гиперпараметров param_grid = {'penalty': ['l2', 'none'], 'solver': ['lbfgs', 'saga']} привело к ухудшению метрики.
<ol>Получены следующие результаты для метрики F1:
<li>тренировочный набор - 0.86;</li>
<li>тестовый набор - 0.78</li>
</ol>
<ol>Расширенный набор гиперпараметров принес следующий результат:
<li>тренировочный набор - 0.85;</li>
<li>тестовый набор - 0.79</li>
</ol>
Приведена тепловая карта зависимости метрики accuracy от solver и С
</p>
<p>Следующий шаг состоял в попытке подобрать оптимальные гиперпараметры, используя RandomizedSearchCV.</br>
<ol>Для простого набора параметров значение метрики F1:
<li>тренировочный набор - 0.87;</li>
<li>тестовый набор - 0.78</li>
</ol>
<ol>Для расширенного набора параметров значение метрики F1:
<li>тренировочный набор - 0.87;</li>
<li>тестовый набор - 0.79</li>
</ol>
</div>
<div>
<h3>Случайный лес</h3>
<p>Для этой модели использовались четыре метода оптимизации</br>
GridSearchCV</br>
<ol>Получены следующие результаты для метрики F1:
<li>тренировочный набор - 0.98;</li>
<li>тестовый набор - 0.7882</li>
</ol>
GridSearchCV</br>
<ol>Получены следующие результаты для метрики F1:
<li>тренировочный набор - 0.98;</li>
<li>тестовый набор - 0.82</li>
</ol>
RandomizedSearchCV</br>
<ol>Получены следующие результаты для метрики F1:
<li>тренировочный набор - 0.97;</li>
<li>тестовый набор - 0.82</li>
</ol>
Hyperopt с использованиенм кросс-валидации</br>
<ol>Получены следующие результаты для метрики F1 (количество итераций - 20):
<li>тренировочный набор - 0.99;</li>
<li>тестовый набор - 0.83</li>
</ol>
<ol>При увеличении количества итераций до 30 получены следующие результаты для метрики F1:
<li>тренировочный набор - 0.99;</li>
<li>тестовый набор - 0.82</li>
</ol>
Optuna</br>
<ol>Получены следующие результаты для метрики F1 (количество итераций - 20):
<li>тренировочный набор - 0.98;</li>
<li>тестовый набор - 0.82</li>
</ol>
</div>





   
